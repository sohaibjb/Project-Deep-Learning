{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "xHDE4_cdq1dz",
        "MiXYFl8ErQxw"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Pathology Detection using GANs\n",
        "\n",
        "This project demonstrates the use of Generative Adversarial Networks (**GANs**) for generating synthetic pathology images. GANs, *introduced by Ian Goodfellow in 2014*, consist of two neural networks—the Generator and the Discriminator—that are trained simultaneously in a zero-sum game framework.\n",
        "\n",
        "In the context of pathology, GANs can be utilized to generate high-quality synthetic images, which are useful for augmenting datasets, improving diagnostic model training, and addressing class imbalance issues in medical imaging datasets. This project adapts a GAN architecture to learn and replicate the distribution of pathology images, with the goal of generating realistic synthetic samples for further applications in medical research.\n",
        "\n",
        "By implementing this model, we aim to:\n",
        "\n",
        "* Explore the potential of GANs for generating pathology images.\n",
        "* Understand how adversarial training can be applied to medical imaging.\n",
        "* Provide a foundation for future work in pathology data augmentation or anomaly detection.\n",
        "\n",
        "This implementation was inspired by a Kaggle project and serves as a hands-on introduction to GANs in medical imaging, using a simple architecture tailored for pathology datasets."
      ],
      "metadata": {
        "id": "HFqMrAkoqmID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importation of the necessary libraries\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "630Af7DbFpW1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Generator model**"
      ],
      "metadata": {
        "id": "xHDE4_cdq1dz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Takes a random noise vector (latent space) and generates\n",
        "synthetic images resembling the training data."
      ],
      "metadata": {
        "id": "JXTOASOqrBx8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim, img_shape):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(1024, img_shape),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        img = self.model(z)\n",
        "        img = img.view(img.size(0), 3, 64, 64)\n",
        "        return img"
      ],
      "metadata": {
        "id": "cB3cVvW_Fuwx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Discriminator Model**"
      ],
      "metadata": {
        "id": "MiXYFl8ErQxw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classifies images as real (from dataset) or fake (from Generator)."
      ],
      "metadata": {
        "id": "a7C6p1AdrVBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, img_shape):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(img_shape, 1024),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        img_flat = img.view(img.size(0), -1)\n",
        "        validity = self.model(img_flat)\n",
        "        return validity\n"
      ],
      "metadata": {
        "id": "G1WhpK_aFx3l"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **GAN Framework**"
      ],
      "metadata": {
        "id": "tUEQCWlnr1xB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combines Generator and Discriminator models and coordinates their training using adversarial loss."
      ],
      "metadata": {
        "id": "u7-Zr8wCsBGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GAN:\n",
        "    def __init__(self, latent_dim, img_shape):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self.generator = Generator(latent_dim, img_shape).to(self.device)\n",
        "        self.discriminator = Discriminator(img_shape).to(self.device)\n",
        "\n",
        "        self.adversarial_loss = nn.BCELoss()\n",
        "        self.generator_optimizer = optim.Adam(self.generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "        self.discriminator_optimizer = optim.Adam(self.discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))"
      ],
      "metadata": {
        "id": "LYK4BgGdsMQb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training loop for the GAN model.\n",
        "\n",
        "        Args:\n",
        "            dataloader: DataLoader object for the training data\n",
        "            num_epochs: Number of training epochs\n",
        "            sample_interval: Interval for saving generated image samples"
      ],
      "metadata": {
        "id": "sgavL4P9sQTq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fBt4pf5SFcbs"
      },
      "outputs": [],
      "source": [
        "    def train(self, dataloader, num_epochs, sample_interval=100):\n",
        "        for epoch in range(num_epochs):\n",
        "            for i, real_images in enumerate(dataloader):\n",
        "                valid = torch.ones(real_images.size(0), 1).to(self.device)\n",
        "                fake = torch.zeros(real_images.size(0), 1).to(self.device)\n",
        "\n",
        "                real_images = real_images.to(self.device)\n",
        "\n",
        "                # //////////////////////////Train Generator///////////////////////////\n",
        "                self.generator_optimizer.zero_grad()\n",
        "\n",
        "                # Generate fake images from random noise\n",
        "                z = torch.randn(real_images.size(0), latent_dim).to(self.device)\n",
        "                generated_images = self.generator(z)\n",
        "\n",
        "                # Compute generator loss (aim to fool discriminator)\n",
        "                g_loss = self.adversarial_loss(self.discriminator(generated_images), valid)\n",
        "                # Backpropagation and optimization step\n",
        "                g_loss.backward()\n",
        "\n",
        "\n",
        "                # //////////////////////////Train Discriminator//////////////////////////\n",
        "                self.generator_optimizer.step()\n",
        "                self.discriminator_optimizer.zero_grad()\n",
        "\n",
        "                # Compute loss for real and fake images\n",
        "                real_loss = self.adversarial_loss(self.discriminator(real_images), valid)\n",
        "                fake_loss = self.adversarial_loss(self.discriminator(generated_images.detach()), fake)\n",
        "\n",
        "                # Average discriminator loss\n",
        "                d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "                # Backpropagation and optimization step\n",
        "                d_loss.backward()\n",
        "                self.discriminator_optimizer.step()\n",
        "\n",
        "                # Log training progress\n",
        "                if i % 100 == 0:\n",
        "                    print(f\"[Epoch {epoch}/{num_epochs}] [Batch {i}/{len(dataloader)}] [D loss: {d_loss.item()}] [G loss: {g_loss.item()}]\")\n",
        "\n",
        "                # Save image samples at intervals\n",
        "                if i % sample_interval == 0:\n",
        "                    self.sample_images(epoch, i)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save generated image samples for visual evaluation.\n",
        "\n",
        "        Args:\n",
        "            epoch: Current epoch number\n",
        "            batch_idx: Current batch index"
      ],
      "metadata": {
        "id": "Z6cGXPGuuAOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    def sample_images(self, epoch, batch_idx):\n",
        "        with torch.no_grad():\n",
        "            z = torch.randn(5, latent_dim).to(self.device)\n",
        "            generated_images = self.generator(z)\n",
        "            save_image(generated_images, f\"C:/Users/BobLoblaw/Desktop/Course Materials/ARI5004/project/generated/sample_{epoch}_{batch_idx}.png\", nrow=5, normalize=True)"
      ],
      "metadata": {
        "id": "2KHlEaH1uBpJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Dataset for Pathology Images\n",
        "class CancerDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.images = os.listdir(root_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.root_dir, self.images[idx])\n",
        "        image = Image.open(img_name).convert(\"RGB\")  # Ensure 3 channels (RGB)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image"
      ],
      "metadata": {
        "id": "VNKvk4M9F6lp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    torch.manual_seed(42)\n",
        "\n",
        "    # Hyperparameters\n",
        "    latent_dim = 100\n",
        "    img_shape = 3 * 64 * 64\n",
        "    batch_size = 4\n",
        "    num_epochs = 5\n",
        "\n",
        "    # Image preprocessing transformations\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((64, 64)),\n",
        "        transforms.ToTensor(), # Convert images to tensors\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to [-1, 1]\n",
        "    ])\n",
        "\n",
        "    # Load dataset and create DataLoader\n",
        "    dataset = CancerDataset(root_dir='', transform=transform)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
        "\n",
        "    gan = GAN(latent_dim, img_shape)\n",
        "    gan.train(dataloader, num_epochs=num_epochs)"
      ],
      "metadata": {
        "id": "_HmFAhXgF76R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}